{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit8f4f289bf8eb478ea3376d50ccfb6ae0",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercicio 2 PCS5024, Mais algoritmos para a base adult kaggle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FuncoesAuxiliares as fa\n",
    "import FuncoesDeMachineLearning as fml\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = f\"Kaggle\\\\adult.csv\"\n",
    "datasetDataFrame = fa.getDataframeInSpecificFormat(datasetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descricao das colunas discretas da base "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describedDataFrame = pd.DataFrame(columns = None)\n",
    "for column in datasetDataFrame.columns:\n",
    "    if (datasetDataFrame[column].dtype == 'object'):\n",
    "        describedDataFrame[column] = datasetDataFrame[column].describe(include=['category'])\n",
    "describedDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDataFrame['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma classes binarias em variaveis binarias"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputName = 'income'\n",
    "datasetDataFrameReducedColumns = datasetDataFrame.copy() \n",
    "datasetDataFrameReducedColumns[outputName] =  datasetDataFrame[\"income\"].map({\"<=50K\":1, \">50K\":0})\n",
    "datasetDataFrameReducedColumns['sex'] =  datasetDataFrame[\"sex\"].map({\"Male\":1, \"Female\":0})\n",
    "# Coluna casado ou não\n",
    "datasetDataFrameReducedColumns[\"marital.status\"] = datasetDataFrameReducedColumns[\"marital.status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\n",
    "datasetDataFrameReducedColumns[\"marital.status\"] = datasetDataFrameReducedColumns[\"marital.status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'],'Married')\n",
    "datasetDataFrameReducedColumns[\"marital.status\"] = datasetDataFrameReducedColumns[\"marital.status\"].map({\"Married\":1, \"Single\":0})\n",
    "# dropa a coluna de education como int\n",
    "datasetDataFrameReducedColumns.drop(['education.num'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem de nulos em cada uma das colunas"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicOfMissingValues = {}\n",
    "sizeOfData = len(datasetDataFrameReducedColumns.index)\n",
    "for column in datasetDataFrameReducedColumns.columns:\n",
    "    dicOfMissingValues[column] = list(datasetDataFrame[column]).count(\"?\")*100/sizeOfData\n",
    "print(\"Porcentagem de '?' em cada coluna \")\n",
    "for key,val in  dicOfMissingValues.items(): \n",
    "    print('{key} - {val:.2f}%'.format(key = key, val = val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove as linhas que possuem valores nulos"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDataFrameWithoutColumnsWithMissingValues = fa.removeLinesWithMissingValues(datasetDataFrameReducedColumns)\n",
    "print(f\"Numero total de linhas = {len(datasetDataFrameReducedColumns.index)}\")\n",
    "print(f\"Numero total de linhas que não possuem valores nulos = {len(datasetDataFrameWithoutColumnsWithMissingValues.index)}\")\n",
    "print(\"Porcentagem de linhas perdidas = \")\n",
    "print(f\"{(1 - len(datasetDataFrameWithoutColumnsWithMissingValues.index)/len(datasetDataFrameReducedColumns.index))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describedDataFrame = pd.DataFrame(columns = None)\n",
    "for column in datasetDataFrameWithoutColumnsWithMissingValues.columns:\n",
    "    if (datasetDataFrameWithoutColumnsWithMissingValues[column].dtype != 'object'):\n",
    "        describedDataFrame[column] = datasetDataFrameWithoutColumnsWithMissingValues[column].describe(include=['category'])\n",
    "describedDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDataFrameWithoutColumnsWithMissingValues['relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostra imagem de correlação"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiesDataFrame = pd.get_dummies(datasetDataFrameWithoutColumnsWithMissingValues)\n",
    "cor = dummiesDataFrame.corr()\n",
    "cor_target = abs(cor[outputName]).sort_values(ascending=False)[1:]\n",
    "cor_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'cor_target' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1736f3ebd0f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnumberOfRelevantVariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcolumnsNamesToBeRemoved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcor_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumberOfRelevantVariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcorrelatedDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummiesDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumnsNamesToBeRemoved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrelatedDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cor_target' is not defined"
     ]
    }
   ],
   "source": [
    "numberOfRelevantVariables = 5\n",
    "columnsNamesToBeRemoved = list(cor_target.keys()[numberOfRelevantVariables:])\n",
    "correlatedDataFrame = dummiesDataFrame.drop(columns = columnsNamesToBeRemoved)\n",
    "plt.figure(figsize=(50,40))\n",
    "cor = correlatedDataFrame.corr()\n",
    "sns.set(font_scale=4)\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds, annot_kws={\"size\": 50})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training validaditon and test sets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfRelevantVariables = 30\n",
    "X_train,X_crossVal, X_test,y_train,y_crossVal, y_test = fa.prepareDatasetforTraining(datasetDataFrameWithoutColumnsWithMissingValues,outputName,numberOfRelevantVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validating algorithms"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knnPerformanceDataFrame = fml.applyKNNWithDifferentHyperparameters(X_train, X_crossVal, y_train, y_crossVal,numberOfRelevantVariables)\n",
    "knnPerformanceDataFrame.to_excel('knnPeformance.xlsx')\n",
    "knnPerformanceDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naieve bayes\n",
    "naiveBayesPerfomanceDataFrame = fml.applyNaiveBayesWithDifferentHyperparameters(X_train, X_crossVal, y_train, y_crossVal,numberOfRelevantVariables)\n",
    "naiveBayesPerfomanceDataFrame.to_excel('NBPeformance.xlsx')\n",
    "naiveBayesPerfomanceDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "logisticRegressionPerformanceDataFrame = fml.applyLogisticRegressionDifferentHyperparameters(X_train, X_crossVal, y_train, y_crossVal,numberOfRelevantVariables)\n",
    "logisticRegressionPerformanceDataFrame.to_excel('LRPeformance.xlsx')\n",
    "logisticRegressionPerformanceDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "decisionTreePerformanceDataFrame = fml.applyDecisionTreeDifferentHyperparameters(X_train, X_crossVal, y_train, y_crossVal,numberOfRelevantVariables)\n",
    "decisionTreePerformanceDataFrame.to_excel('DTPeformance.xlsx')\n",
    "decisionTreePerformanceDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "randomForestPerformanceDataFrame = fml.applyRandomForestDifferentHyperparameters(X_train, X_crossVal, y_train, y_crossVal,numberOfRelevantVariables)\n",
    "randomForestPerformanceDataFrame.to_excel('RFPeformance.xlsx')\n",
    "randomForestPerformanceDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento final:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train = np.concatenate((X_train, X_crossVal), axis=0)\n",
    "y_new_train = np.concatenate((y_train, y_crossVal), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'datasetDataFrameWithoutColumnsWithMissingValues' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3ba51205ec86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnumberOfRelevantVariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_new_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_new_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepareDatasetforTrainingComparationWithKaggle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasetDataFrameWithoutColumnsWithMissingValues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumberOfRelevantVariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrandomForestPerformanceDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplyRandomForestDifferentHyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_new_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumberOfRelevantVariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrandomForestPerformanceDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasetDataFrameWithoutColumnsWithMissingValues' is not defined"
     ]
    }
   ],
   "source": [
    "numberOfRelevantVariables = 30\n",
    "X_new_train,y_new_train,X_test,y_test = fa.prepareDatasetforTrainingComparationWithKaggle(datasetDataFrameWithoutColumnsWithMissingValues,outputName,numberOfRelevantVariables)\n",
    "randomForestPerformanceDataFrame = fml.applyRandomForestDifferentHyperparameters(X_new_train, X_test, y_new_train, y_test,numberOfRelevantVariables)\n",
    "randomForestPerformanceDataFrame"
   ]
  }
 ]
}